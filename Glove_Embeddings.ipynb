{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('F:/QA_with_NN/here_is_your_answer/dev-v2.0.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get data in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data\n",
    "\n",
    "train_data_list = []\n",
    "context = []\n",
    "question = []\n",
    "answer = []\n",
    "answer_start = []\n",
    "is_impossible = []\n",
    "example = []\n",
    "\n",
    "for i in range(len(train['data'])):\n",
    "    for j in range(len(train['data'][i]['paragraphs'])):\n",
    "        context.append(train['data'][i]['paragraphs'][j]['context'])\n",
    "        for k in range(len(train['data'][i]['paragraphs'][j]['qas'])):\n",
    "            question.append(train['data'][i]['paragraphs'][j]['qas'][k]['question'])\n",
    "            is_impossible.append(train['data'][i]['paragraphs'][j]['qas'][k]['is_impossible'])\n",
    "            for l in range(len(train['data'][i]['paragraphs'][j]['qas'][k]['answers'])):\n",
    "                answer.append(train['data'][i]['paragraphs'][j]['qas'][k]['answers'][l]['text'])\n",
    "                answer_start.append(train['data'][i]['paragraphs'][j]['qas'][k]['answers'][l]['answer_start'])\n",
    "               \n",
    "\n",
    "for i in range(len(train['data'])):\n",
    "    for j in range(len(train['data'][i]['paragraphs'])):\n",
    "        context_1 = train['data'][i]['paragraphs'][j]['context']\n",
    "        for k in range(len(train['data'][i]['paragraphs'][j]['qas'])):\n",
    "            question_1 = train['data'][i]['paragraphs'][j]['qas'][k]['question']\n",
    "            is_impossible_1 = train['data'][i]['paragraphs'][j]['qas'][k]['is_impossible']\n",
    "            if is_impossible_1 == False:\n",
    "                for l in range(len(train['data'][i]['paragraphs'][j]['qas'][k]['answers'])):\n",
    "                    answer_1 = train['data'][i]['paragraphs'][j]['qas'][k]['answers'][l]['text']\n",
    "                    answer_start_1 = train['data'][i]['paragraphs'][j]['qas'][k]['answers'][l]['answer_start']\n",
    "            else:  \n",
    "                answer_1 = \"\"\n",
    "                answer_start_1= \"\"\n",
    "            example.append((context_1, question_1, is_impossible_1, answer_1, answer_start_1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.',\n",
       " 'When were the Normans in Normandy?',\n",
       " False,\n",
       " '10th and 11th centuries',\n",
       " 94)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[1]\n",
    "#  context, question, is_impossible, answer, answer_start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11873"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking only on 3 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>In what country is Normandy located?</td>\n",
       "      <td>False</td>\n",
       "      <td>France</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>When were the Normans in Normandy?</td>\n",
       "      <td>False</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>From which countries did the Norse originate?</td>\n",
       "      <td>False</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  The Normans (Norman: Nourmands; French: Norman...   \n",
       "1  The Normans (Norman: Nourmands; French: Norman...   \n",
       "2  The Normans (Norman: Nourmands; French: Norman...   \n",
       "\n",
       "                                        question  is_impossible  \\\n",
       "0           In what country is Normandy located?          False   \n",
       "1             When were the Normans in Normandy?          False   \n",
       "2  From which countries did the Norse originate?          False   \n",
       "\n",
       "                        answer answer_start  \n",
       "0                       France          159  \n",
       "1      10th and 11th centuries           94  \n",
       "2  Denmark, Iceland and Norway          256  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataframe = pd.DataFrame(example)\n",
    "df = dataframe.head(3)\n",
    "df.columns = ['context', 'question', 'is_impossible', 'answer', 'answer_start']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create vocab file, tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "go through every file (train and validaton: context and question) and then get distinct words saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bijno\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences :  [[1, 8, 10, 19, 20, 21, 22, 23, 9, 1, 24, 11, 5, 1, 12, 2, 25, 13, 26, 7, 27, 4, 17, 28, 29, 5, 30, 31, 9, 32, 6, 18, 10, 33, 6, 34, 35, 2, 36, 6, 37, 38, 2, 39, 11, 40, 7, 41, 42, 43, 4, 44, 45, 4, 46, 47, 48, 3, 14, 15, 49, 50, 3, 51, 2, 52, 16, 1, 53, 54, 2, 55, 56, 57, 7, 58, 59, 60, 61, 16, 1, 62, 63, 64, 3, 14, 15, 1, 65, 66, 2, 67, 68, 3, 1, 8, 69, 70, 5, 1, 71, 72, 3, 1, 12, 73, 2, 74, 75, 4, 76, 77, 1, 78, 13], [5, 79, 80, 81, 17, 82], [1, 8, 10, 19, 20, 21, 22, 23, 9, 1, 24, 11, 5, 1, 12, 2, 25, 13, 26, 7, 27, 4, 17, 28, 29, 5, 30, 31, 9, 32, 6, 18, 10, 33, 6, 34, 35, 2, 36, 6, 37, 38, 2, 39, 11, 40, 7, 41, 42, 43, 4, 44, 45, 4, 46, 47, 48, 3, 14, 15, 49, 50, 3, 51, 2, 52, 16, 1, 53, 54, 2, 55, 56, 57, 7, 58, 59, 60, 61, 16, 1, 62, 63, 64, 3, 14, 15, 1, 65, 66, 2, 67, 68, 3, 1, 8, 69, 70, 5, 1, 71, 72, 3, 1, 12, 73, 2, 74, 75, 4, 76, 77, 1, 78, 13], [83, 9, 1, 8, 5, 17], [1, 8, 10, 19, 20, 21, 22, 23, 9, 1, 24, 11, 5, 1, 12, 2, 25, 13, 26, 7, 27, 4, 17, 28, 29, 5, 30, 31, 9, 32, 6, 18, 10, 33, 6, 34, 35, 2, 36, 6, 37, 38, 2, 39, 11, 40, 7, 41, 42, 43, 4, 44, 45, 4, 46, 47, 48, 3, 14, 15, 49, 50, 3, 51, 2, 52, 16, 1, 53, 54, 2, 55, 56, 57, 7, 58, 59, 60, 61, 16, 1, 62, 63, 64, 3, 14, 15, 1, 65, 66, 2, 67, 68, 3, 1, 8, 69, 70, 5, 1, 71, 72, 3, 1, 12, 73, 2, 74, 75, 4, 76, 77, 1, 78, 13], [6, 84, 85, 86, 1, 18, 87]] \n",
      "\n",
      "word_index :  {'the': 1, 'and': 2, 'of': 3, 'to': 4, 'in': 5, 'from': 6, 'their': 7, 'normans': 8, 'were': 9, 'norman': 10, 'who': 11, '10th': 12, 'centuries': 13, 'west': 14, 'francia': 15, 'with': 16, 'normandy': 17, 'norse': 18, 'nourmands': 19, 'french': 20, 'normands': 21, 'latin': 22, 'normanni': 23, 'people': 24, '11th': 25, 'gave': 26, 'name': 27, 'a': 28, 'region': 29, 'france': 30, 'they': 31, 'descended': 32, 'comes': 33, 'norseman': 34, 'raiders': 35, 'pirates': 36, 'denmark': 37, 'iceland': 38, 'norway': 39, 'under': 40, 'leader': 41, 'rollo': 42, 'agreed': 43, 'swear': 44, 'fealty': 45, 'king': 46, 'charles': 47, 'iii': 48, 'through': 49, 'generations': 50, 'assimilation': 51, 'mixing': 52, 'native': 53, 'frankish': 54, 'roman': 55, 'gaulish': 56, 'populations': 57, 'descendants': 58, 'would': 59, 'gradually': 60, 'merge': 61, 'carolingian': 62, 'based': 63, 'cultures': 64, 'distinct': 65, 'cultural': 66, 'ethnic': 67, 'identity': 68, 'emerged': 69, 'initially': 70, 'first': 71, 'half': 72, 'century': 73, 'it': 74, 'continued': 75, 'evolve': 76, 'over': 77, 'succeeding': 78, 'what': 79, 'country': 80, 'is': 81, 'located': 82, 'when': 83, 'which': 84, 'countries': 85, 'did': 86, 'originate': 87}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "sentences_list = []\n",
    "\n",
    "for eachRow in df.itertuples():\n",
    "    sentences_list.append(eachRow.context)\n",
    "    sentences_list.append(eachRow.question)\n",
    "\n",
    "t  = tf.keras.preprocessing.text.Tokenizer()\n",
    "\n",
    "fit_text = sentences_list\n",
    "\n",
    "#fit_on_texts fits on sentences when list of sentences is passed to fit_on_texts() function. \n",
    "#ie - fit_on_texts( [ sent1, sent2, sent3,....sentN ] )\n",
    "t.fit_on_texts(fit_text)\n",
    "\n",
    "#Similarly, list of sentences/single sentence in a list must be passed into texts_to_sequences.\n",
    "\n",
    "sequences = t.texts_to_sequences(sentences_list)\n",
    "\n",
    "print('sequences : ',sequences,'\\n')\n",
    "\n",
    "print('word_index : ',t.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save word vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.platform import gfile\n",
    "save_vocab_path = 'F:/QA_with_NN/here_is_your_answer'\n",
    "vocab_list = t.word_index\n",
    "with gfile.GFile(save_vocab_path + \"/vocab.dat\", mode='w') as vocab_file:\n",
    "    for w in vocab_list:\n",
    "        vocab_file.write(w + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the\\n', 'and\\n', 'of\\n', 'to\\n', 'in\\n', 'from\\n', 'their\\n', 'normans\\n', 'were\\n', 'norman\\n', 'who\\n', '10th\\n', 'centuries\\n', 'west\\n', 'francia\\n', 'with\\n', 'normandy\\n', 'norse\\n', 'nourmands\\n', 'french\\n', 'normands\\n', 'latin\\n', 'normanni\\n', 'people\\n', '11th\\n', 'gave\\n', 'name\\n', 'a\\n', 'region\\n', 'france\\n', 'they\\n', 'descended\\n', 'comes\\n', 'norseman\\n', 'raiders\\n', 'pirates\\n', 'denmark\\n', 'iceland\\n', 'norway\\n', 'under\\n', 'leader\\n', 'rollo\\n', 'agreed\\n', 'swear\\n', 'fealty\\n', 'king\\n', 'charles\\n', 'iii\\n', 'through\\n', 'generations\\n', 'assimilation\\n', 'mixing\\n', 'native\\n', 'frankish\\n', 'roman\\n', 'gaulish\\n', 'populations\\n', 'descendants\\n', 'would\\n', 'gradually\\n', 'merge\\n', 'carolingian\\n', 'based\\n', 'cultures\\n', 'distinct\\n', 'cultural\\n', 'ethnic\\n', 'identity\\n', 'emerged\\n', 'initially\\n', 'first\\n', 'half\\n', 'century\\n', 'it\\n', 'continued\\n', 'evolve\\n', 'over\\n', 'succeeding\\n', 'what\\n', 'country\\n', 'is\\n', 'located\\n', 'when\\n', 'which\\n', 'countries\\n', 'did\\n', 'originate\\n']\n",
      "~~~~~~~~\n",
      "['the', 'and', 'of', 'to', 'in', 'from', 'their', 'normans', 'were', 'norman', 'who', '10th', 'centuries', 'west', 'francia', 'with', 'normandy', 'norse', 'nourmands', 'french', 'normands', 'latin', 'normanni', 'people', '11th', 'gave', 'name', 'a', 'region', 'france', 'they', 'descended', 'comes', 'norseman', 'raiders', 'pirates', 'denmark', 'iceland', 'norway', 'under', 'leader', 'rollo', 'agreed', 'swear', 'fealty', 'king', 'charles', 'iii', 'through', 'generations', 'assimilation', 'mixing', 'native', 'frankish', 'roman', 'gaulish', 'populations', 'descendants', 'would', 'gradually', 'merge', 'carolingian', 'based', 'cultures', 'distinct', 'cultural', 'ethnic', 'identity', 'emerged', 'initially', 'first', 'half', 'century', 'it', 'continued', 'evolve', 'over', 'succeeding', 'what', 'country', 'is', 'located', 'when', 'which', 'countries', 'did', 'originate']\n",
      "~~~~~~~~\n",
      "{'the': 0, 'and': 1, 'of': 2, 'to': 3, 'in': 4, 'from': 5, 'their': 6, 'normans': 7, 'were': 8, 'norman': 9, 'who': 10, '10th': 11, 'centuries': 12, 'west': 13, 'francia': 14, 'with': 15, 'normandy': 16, 'norse': 17, 'nourmands': 18, 'french': 19, 'normands': 20, 'latin': 21, 'normanni': 22, 'people': 23, '11th': 24, 'gave': 25, 'name': 26, 'a': 27, 'region': 28, 'france': 29, 'they': 30, 'descended': 31, 'comes': 32, 'norseman': 33, 'raiders': 34, 'pirates': 35, 'denmark': 36, 'iceland': 37, 'norway': 38, 'under': 39, 'leader': 40, 'rollo': 41, 'agreed': 42, 'swear': 43, 'fealty': 44, 'king': 45, 'charles': 46, 'iii': 47, 'through': 48, 'generations': 49, 'assimilation': 50, 'mixing': 51, 'native': 52, 'frankish': 53, 'roman': 54, 'gaulish': 55, 'populations': 56, 'descendants': 57, 'would': 58, 'gradually': 59, 'merge': 60, 'carolingian': 61, 'based': 62, 'cultures': 63, 'distinct': 64, 'cultural': 65, 'ethnic': 66, 'identity': 67, 'emerged': 68, 'initially': 69, 'first': 70, 'half': 71, 'century': 72, 'it': 73, 'continued': 74, 'evolve': 75, 'over': 76, 'succeeding': 77, 'what': 78, 'country': 79, 'is': 80, 'located': 81, 'when': 82, 'which': 83, 'countries': 84, 'did': 85, 'originate': 86}\n"
     ]
    }
   ],
   "source": [
    "vocabulary_path =save_vocab_path + \"/vocab.dat\"\n",
    "\n",
    "# word embeddings\n",
    "word_embed = []\n",
    "with gfile.GFile(vocabulary_path, mode=\"r\") as f:\n",
    "    word_embed.extend(f.readlines())\n",
    "print(word_embed)\n",
    "print('~~~~~~~~')\n",
    "\n",
    "word_embed = [line.strip('\\n') for line in word_embed]\n",
    "print(word_embed)\n",
    "print('~~~~~~~~')\n",
    "vocab = dict([(x, y) for (y, x) in enumerate(word_embed)])\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glove\n",
    "\n",
    "create/save matrix of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/QA_with_NN/here_is_your_answer/glove.6B.100d.txt \n",
      " F:/QA_with_NN/here_is_your_answer/glove.trimmed.100.npz\n",
      "[[ 0.3332733  -0.94513552 -1.41157961 ... -0.51447646 -1.34378934\n",
      "   0.59916489]\n",
      " [-0.18443638 -0.94481042  1.06892479 ...  1.3293421   1.9535416\n",
      "  -1.37298313]\n",
      " [ 1.65306163 -0.3523557  -1.07335513 ...  1.16581942 -0.67092896\n",
      "  -0.8068626 ]\n",
      " ...\n",
      " [-1.27899692 -0.64690939 -0.56726003 ...  0.36274502  1.54547118\n",
      "   0.31178795]\n",
      " [ 1.05757551  0.55187562  0.93242399 ...  0.514478    1.30144369\n",
      "   2.03318395]\n",
      " [ 0.75228839  2.28612678 -0.2355252  ...  0.92382591 -0.53914566\n",
      "  -1.04749012]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "glove_dim = 100\n",
    "glove_path = save_vocab_path + \"/glove.6B.{}d.txt\".format(glove_dim)\n",
    "\n",
    "# matrix of embeddings\n",
    "glove = np.random.randn(len(word_embed), glove_dim)\n",
    "save_path = save_vocab_path + \"/glove.trimmed.{}\".format(glove_dim) + \".npz\"\n",
    "\n",
    "print(glove_path, '\\n', save_path)\n",
    "print(glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from tqdm import *\n",
    "file_size = 1e5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/87 of word vocab have corresponding vectors in F:/QA_with_NN/here_is_your_answer/glove.6B.100d.txt\n",
      "saved trimmed glove matrix at: F:/QA_with_NN/here_is_your_answer/glove.trimmed.100.npz\n"
     ]
    }
   ],
   "source": [
    "found = 0\n",
    "with open(glove_path, 'r') as fh:\n",
    "    for line in tqdm(fh, total=file_size):\n",
    "        array = line.lstrip().rstrip().split(\" \")\n",
    "        word = array[0]\n",
    "        vector = list(map(float, array[1:]))\n",
    "        print(line, array, word, vector)\n",
    "        if word in word_embed:\n",
    "            idx = word_embed.index(word)\n",
    "            glove[idx, :] = vector\n",
    "            found += 1\n",
    "            print('word', idx, glove[idx, :])\n",
    "        if word.capitalize() in word_embed:\n",
    "            idx = word_embed.index(word.capitalize())\n",
    "            glove[idx, :] = vector\n",
    "            found += 1\n",
    "            print('wordcapitalize', idx, glove[idx, :])\n",
    "        if word.upper() in word_embed:\n",
    "            idx = word_embed.index(word.upper())\n",
    "            glove[idx, :] = vector\n",
    "            found += 1\n",
    "            print('wordupper', idx, glove[idx, :])\n",
    "\n",
    "\n",
    "print(\"{}/{} of word vocab have corresponding vectors in {}\".format(found, len(word_embed), glove_path))\n",
    "np.savez_compressed(save_path, glove=glove)\n",
    "print(\"saved trimmed glove matrix at: {}\".format(save_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QC saved glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['glove']\n",
      "[[ 0.3332733  -0.94513552 -1.41157961 ... -0.51447646 -1.34378934\n",
      "   0.59916489]\n",
      " [-0.18443638 -0.94481042  1.06892479 ...  1.3293421   1.9535416\n",
      "  -1.37298313]\n",
      " [ 1.65306163 -0.3523557  -1.07335513 ...  1.16581942 -0.67092896\n",
      "  -0.8068626 ]\n",
      " ...\n",
      " [-1.27899692 -0.64690939 -0.56726003 ...  0.36274502  1.54547118\n",
      "   0.31178795]\n",
      " [ 1.05757551  0.55187562  0.93242399 ...  0.514478    1.30144369\n",
      "   2.03318395]\n",
      " [ 0.75228839  2.28612678 -0.2355252  ...  0.92382591 -0.53914566\n",
      "  -1.04749012]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'F:/QA_with_NN/here_is_your_answer/glove.trimmed.100.npz' #, 'r') as file:\n",
    "d = np.load(file)\n",
    "print(d.files)\n",
    "print(d['glove'])\n",
    "\n",
    "glove == d['glove']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
